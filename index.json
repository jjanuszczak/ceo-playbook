[{"content":"","date":"27 November 2025","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":"Guidance for leaders navigating digital transformation. These articles draw on my experience as a CEO, advisor, and venture builder to help organizations make better choices and unlock growth. While the focus is on strategy and leadership, I occasionally dive into the technical side of emerging technologies—because understanding how things truly work is essential to leading them.\n","date":"27 November 2025","externalUrl":null,"permalink":"/articles/","section":"Articles","summary":"","title":"Articles","type":"articles"},{"content":"","date":"27 November 2025","externalUrl":null,"permalink":"/tags/digital-transformation/","section":"Tags","summary":"","title":"Digital Transformation","type":"tags"},{"content":"","date":"27 November 2025","externalUrl":null,"permalink":"/","section":"John Januszczak | Fintech \u0026 Innovation Strategy","summary":"","title":"John Januszczak | Fintech \u0026 Innovation Strategy","type":"page"},{"content":"","date":"27 November 2025","externalUrl":null,"permalink":"/tags/leadership/","section":"Tags","summary":"","title":"Leadership","type":"tags"},{"content":"","date":"27 November 2025","externalUrl":null,"permalink":"/tags/strategy/","section":"Tags","summary":"","title":"Strategy","type":"tags"},{"content":"","date":"27 November 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"Reflections on MIT’s “State of AI in Business 2025” Report\nOne statistic that reverberated loudly this year: 95% of organizations are getting zero return on their GenAI investments. Not low returns. Not “early returns.” Zero.\nMIT’s State of AI in Business 2025 report makes it clear that this failure is not about models, regulation, or budgets. It is about approach, and more importantly, a profound misunderstanding among business leaders of what AI actually is and how it transforms organizations.\nAfter reading the report and reflecting on my own experience building digital businesses, leading shared service transformations, and running a fintech that processed billions in annual transaction volume, the diagnosis is clear:\nGenAI is not failing. Leaders are failing to understand the paradigm shift.\nBelow are my key insights and takeaways.\nProductivity ≠ P\u0026amp;L Impact. This Is Where Most Strategies Die # MIT notes that tools like ChatGPT and Copilot are achieving widespread adoption, but primarily as individual productivity tools, not drivers of enterprise value. Enterprises confuse activity with impact. Just because your workforce is generating better emails doesn’t mean your company is transforming.\nThe report highlights a critical disconnect: ChatGPT improves individual output. But has almost no influence on corporate workflows, cost structures, or revenue lines. This aligns with what I see in real-world transformations: organizations are excited to “use AI” but rarely redesign the core processes where real value is created.\nAI doesn’t create P\u0026amp;L impact unless it replaces something expensive. Usually external. The MIT report reinforces this. For one best in class organization covered in the study:\nBPO elimination = $2M–$10M annual savings Agency replacement = 30% reduction Vendor consolidation = millions saved That’s real money. And it explains why countries like the Philippines, home to massive BPO sectors, should be paying attention. The structural implications are significant.\nThe Real Divide Isn’t Technical. It’s Organizational # The report’s central argument is brilliantly summarized: The dividing line is not intelligence; it’s memory, adaptability, and learning capability. AI that doesn’t learn might be more akin to autocomplete with better grammar. This matters because enterprises still operate under a pre-AI architecture. They’re built around static tools, rigid processes, and departments that don’t talk to each other.\nBut GenAI isn’t a tool. It’s a learning system. And learning systems only deliver value when:\nThey integrate into workflows They remember context They adapt faster than humans can patch them Most enterprise AI fails precisely because:\nIt has no memory It can’t evolve It breaks in edge cases It doesn’t match how the business actually works Executives evaluate AI like they evaluate SaaS. But AI is not SaaS. It’s a fundamentally different class of technology.\nShadow AI: The Most Important Signal Boards Are Ignoring # One of the most fascinating insights from the report: 90% of employees use AI for work. Only 40% of companies have purchased an AI subscription.. This is the “shadow AI economy.” Employees have already crossed the divide. Enterprises have not.\nThis should keep executives awake at night, not because of risk, but because of what it signals: Your workforce knows what \u0026ldquo;good AI\u0026rdquo; looks like. And they will quietly reject anything worse.\nI’ve seen this firsthand in digital transformations:\nIf the official tool is slow → people circumvent it If the tool is rigid → spreadsheets reappear If the workflow doesn’t match reality → shadow systems emerge Shadow AI is the new “spreadsheet problem,” but at 100x the speed and complexity.\nMore importantly: shadow AI reveals the real use cases. The ones your employees already value. Smart leaders will learn from this rather than resist it.\nThe Successful Startup Playbook Lives On # MIT’s findings match what I’ve observed mentoring founders and investing in startups, regardless of whether it involves AI or not: winners go narrow and deep. Losers go broad and shallow.\nAccording to the report, startups that cross the divide:\nStart with a single painful workflow Achieve visible value in days or weeks Learn from feedback immediately Embed deeply into existing systems Expand outward only after winning a foothold And importantly: Trust and distribution matter more than the underlying model. MIT notes that successful startups close deals by:\nLeveraging system integrators Partnering with BPOs Using board and executive referrals Riding existing enterprise procurement channels This is classic enterprise sales. GenAI hasn’t changed it. What has changed is that the strongest moats are being built around:\nWorkflow integration Domain-specific memory Organizational learning Not around models.\nThe Enterprise Model Is Already Shifting: From Software to Services # In a way, enterprises have really always purchased services (albeit packaged as software). The report offers a subtle insight that many will miss:\n“Successful buyers treat AI vendors more like BPO providers than SaaS companies.”\nThis is huge as it makes what was often implied explicit: enterprises don’t want tools. They want outcomes. And they want vendors accountable for those outcomes.\nThis shift mirrors what I saw at UBX as we moved toward embedded finance and managed services:\nClients no longer wanted the plumbing They wanted the result: instant payments, automated lending, reconciled settlements And they wanted commercial models aligned to outcomes, not licenses GenAI is following the same trajectory. Enterprises will cross the divide when they stop buying software and start buying capability. This aligns perfectly with the concept of AI being packaged as agents. Some solutions even give their AI agents names!\nThe Next Architectural Shift: The Agentic Web # MIT closes with a view of the near future that aligns strongly with what I see happening: the rise of the Agentic Web. Systems of interoperable, learning, memory-rich agents coordinating across the enterprise. This is not science fiction. The infrastructure is already here in the form of evolving agent frameworks.\nThis evolution is exactly what may allow enterprises to:\nReplace BPOs Automate back-office operations Achieve zero-touch processes Generate exponential learning loops When people talk about “AI replacing jobs,” they often misunderstand. The more relevant shift is that AI may replace entire categories of outsourced workflows before it replaces internal roles.\nThe implications for countries like the Philippines are profound.\nWhat Leaders Should Do Now # Based on MIT’s data and my own experience, here are the strategic imperatives:\nStop Piloting. Start Integrating. Pilots are where AI goes to die. Integration is where value lives. Buy, Don’t Build, unless the process is uniquely mission-critical. MIT’s data: external builds succeed twice as often as internal ones. Focus on back-office automation. This is where the hidden ROI lives, and where BPO-heavy organizations can gain the most. Empower line managers, not central AI labs. Your power users already know where AI creates value. Choose tools that learn. Anything static is obsolete before deployment. AI Isn’t a Technology Problem. It’s a Leadership Problem # MIT’s research echoes what I’ve seen across three decades of digital transformation in banking, insurance, government, and fintech: AI rewards organizations that are willing to redesign themselves. It punishes those that try to bolt innovation onto old structures.\nThe GenAI Divide is not a gap in capability. It’s a gap in imagination.\nThe winners won’t be the companies that try AI. They’ll be the ones that let AI change how they work.\nAnd that window, as MIT warns, is closing fast.\n","date":"27 November 2025","externalUrl":null,"permalink":"/articles/mit-ai-report-2025/","section":"Articles","summary":"MIT’s 2025 State of AI in Business report reveals a stark truth: 95% of enterprises get zero ROI from GenAI. The problem isn’t the technology—it’s the approach. In this analysis, I break down the real causes of failure and what leaders must do to cross the GenAI Divide.","title":"The GenAI Divide: Why 95% Still Get Zero ROI","type":"articles"},{"content":"","date":"25 November 2025","externalUrl":null,"permalink":"/tags/governance/","section":"Tags","summary":"","title":"Governance","type":"tags"},{"content":"There’s a story from my earlier corporate years that has stayed with me. Not because it was dramatic, but because of what it reveals about how organizations fail to think.\nBack then, global compute and storage costs were brutally high. Every gigabyte mattered. IT was viewed strictly as a cost center. Expensive, necessary, and tightly governed. And so, a mandate came down from on high:\nEveryone needed to reduce the size of their email inboxes and folders.\nTo enforce it, the company implemented a hard storage cap. If you hit the limit, your email simply stopped sending and receiving until you purged old messages.\nAcross the organization, people dutifully deleted years of archived emails: project histories, negotiations, customer conversations, decisions made and undone, design debates, strategy discussions, leadership missteps, and breakthroughs.\nAll of it gone.\nAt the time, it felt like housekeeping. In hindsight, it was the mass destruction of an unrecognized asset.\nA decade later, leading digital and data transformations, I realized the magnitude of that loss. That deleted email corpus would have been an extraordinary training dataset for generative AI. It represented institutional memory, behavioral patterns, decision heuristics, operational nuance, and the tacit knowledge that no document management system ever truly captures.\nWe didn’t just reduce storage costs. We erased the raw material of future intelligence.\nThe Strategic Error Behind the Error # Looking back, the mistake wasn’t the storage cap itself. It was the mindset.\nIT was treated as a cost to minimize, not a capability to unlock. When technology is framed as a cost center, the instinct is to shrink, prune, and constrain. You don’t ask, “What new value might this create?” You ask, “What can we cut?”\nData was not yet understood as an asset. At the time, storage was a financial cost; data was a liability risk. Nobody imagined a future where the everyday byproducts of work would power entirely new classes of intelligence.\nEfficiency trumped foresight. The mandate optimized for today’s budget, not tomorrow’s opportunity. It solved a short-term operational problem at the expense of long-term strategic potential.\nThe Irony: The very emails we were told to delete could have trained models that would eventually automate, enhance, or replace half the work described in those same emails.\nWe Weren’t Wrong. We Were Early. # It’s easy to look back and shake our heads. But the truth is: no one knew. Generative AI wasn’t in the lexicon. Storage cost economics were still restrictive. Data privacy frameworks were designed to reduce exposure, not enable intelligence.\nBut today, we do know.\nToday, leaders understand that data is the differentiator. Storage is cheap. Compute is elastic. Models improve by learning from the specific organization they serve.\nThe Real Lesson: Don’t Make Tomorrow’s AI Dumber By Accident # If the 2000s were the era of deletion, the 2020s must be the era of deliberate retention. Not reckless hoarding, but retention with purpose.\n1. Treat data as a strategic asset, not a storage liability.\nIf you believe AI will shape competitive advantage, then you must protect the training fuel. That means implementing governance that values preservation as much as it values compliance.\n2. Don’t optimize for today’s costs at tomorrow’s expense.\nGenerative AI rewards the organizations that understand themselves best. What looks like “operational exhaust” today might be the most valuable dataset in your company 10 years from now.\n3. Build institutional memory that outlives turnover.\nPeople leave. Email gets archived. Documents get lost. AI, properly designed, can preserve narrative continuity across years, roles, and leadership cycles.\n4. Beware the hidden opportunity cost of small decisions.\nThe storage cap was, on paper, a tiny policy change. In impact, it was a decade-long strategic downgrade. This is true of many seemingly minor IT decisions: data retention settings, API access rules, log storage policies, file expiration defaults. Each one constrains future intelligence.\nThe Small Things Matter # The lesson from that deleted email history is not to keep everything forever. It’s that the mundane often becomes meaningful in hindsight.\nLeaders today must ask: What are we deleting now that future AI will wish we hadn’t?\nAre we pruning log files? Are we discarding support chats? Are we de-duplicating customer histories? Are we shrinking telemetry windows? Are we archiving away cultural signatures? If generative AI is to become the cognitive companion to business (predicting, advising, drafting, optimizing), then the richness of what it can do will come from the richness of what we choose to keep.\nThe Strategic Mandate # As organizations rethink their data and AI strategies, this principle must become non-negotiable:\nBuild for the future where AI needs to learn from us. Not the past where storage was expensive.\nIf you ever needed a parable to illustrate the cost of getting it wrong, remember the terabytes of email knowledge we once deleted just to save on disk space.\nA decade later, the bill for that decision finally arrived. And it came in the currency of lost intelligence.\n","date":"25 November 2025","externalUrl":null,"permalink":"/articles/deleted-emails/","section":"Articles","summary":"A strategic retrospective on how the corporate storage caps of the 2000s inadvertently destroyed valuable AI training data—and the mandate for today\u0026rsquo;s leaders to practice deliberate retention.","title":"The Emails We Deleted, The Value We Never Saw Coming","type":"articles"},{"content":"Drawing on two decades of leadership in financial services, I help organizations navigate regulatory complexity, digital transformation, and growth strategy.\nI’m always interested in connecting with fellow innovators in the fintech and banking sectors. Reach out regarding speaking engagements, media commentary, or potential advisory partnerships. If you have a complex challenge you are trying to solve, I’d love to hear about it.\n✅ Message Sent! Thank you for reaching out.\nName Email Message Get in Touch ","date":"24 November 2025","externalUrl":null,"permalink":"/contact/","section":"John Januszczak | Fintech \u0026 Innovation Strategy","summary":"","title":"Let's Build What's Next","type":"page"},{"content":"Why Strategy Should Never Begin With Pre-Work: Lessons From Roger Martin’s “Strategy as Choices”\nFor anyone who has spent time inside a large corporation, the annual strategy cycle is painfully familiar: weeks of pre-work, decks prepared by every function, one-off “strategic inputs” from planning teams and consultants, and a leadership offsite that feels more like a compliance ritual than an exercise in strategic thinking.\nRoger Martin, whose strategy as a set of choices framework has shaped some of the best strategy work in business, argues that this entire approach gets strategy backwards. After revisiting his article How to Prepare for Strategy, and comparing it with my own experience leading transformation and growth in financial services and fintech, I believe Martin’s critique deserves far more attention, especially among leadership teams who wonder why their strategy “process” rarely produces strategic clarity.\nBelow is my take on the core ideas and what they mean for executives, boards, and strategy advisors alike.\n1. Strategy Begins With the Gap Between Intent and Outcome # Martin makes a deceptively simple point: The only productive starting point for strategy is the mismatch between what leadership intended and what actually happened.\nNot market trends. Not competitor analysis. Not long lists of initiatives.\nStrategy begins with truth.\nTo put it plainly: What did we want? What did we choose? What happened? And why did those choices fail or succeed?\nAs a CEO, this resonates deeply. The most honest conversations I’ve had with boards or leadership teams always began with this gap because that gap exposes the causal logic behind past decisions. If you cannot explain why your previous choices produced the results they did, you have no foundation for choosing differently.\nThis is the real work. Everything else is noise.\n2. Strategy Is a Leadership Function—Not a Committee Exercise # Martin is unequivocal: Strategy cannot be delegated.\nNot to Corporate Planning. Not to consultants. Not to the mid-management “strategy working group.”\nOnly the executive leadership team (ELT) can own strategy, because only they own the choices that allocate capital, talent, risk, and reputation.\nThis mirrors how I think about values inside a company. You cannot outsource the creation of values, because values are meaningless unless lived by leaders. Strategy is the same. If strategy is produced by staff, consultants, or analysts, you will get a plan, not a set of choices. And a plan—no matter how well formatted—does not guarantee commitment or coherence.\nThere is nothing more dangerous than a company whose staff-defined “strategy” contradicts the intent of the leaders who are accountable to shareholders.\n3. The Hidden Danger of Pre-Work # In most corporations, pre-work is seen as a way to “prepare” for strategy. Martin argues the opposite: pre-work—especially done without the ELT—creates bias and false certainty.\nIt is a way for someone else to set the agenda. It “loads the dice” with preferred data. It nudges leaders toward predetermined conclusions.\nAnd in many cases, this pre-work becomes so elaborate that it replaces strategic thinking entirely.\nI have seen this repeatedly: an internal strategy team or a consultant comes in with a heavy deck full of facts no one asked for, crafted to steer leadership toward a conclusion that was decided long before the offsite.\nIn this sense, pre-work is not preparation. It is contamination.\nThe only legitimate pre-work is answering the questions inside the heads of the ELT and the board—not what someone else thinks they should be thinking about.\n4. Facts Matter. Decks Don’t # Martin emphasizes that strategy teams should not be producing decks. Their job is to curate a concise fact base—and only the facts directly relevant to the choices leaders must grapple with.\nThis is not analysis for analysis’s sake. This is data with utility.\nIn my own advisory work, I always ask: Will this fact change a choice? If the answer is no, it’s noise.\nThe value of analysis lies not in volume, but in clarity.\n5. Strategy Is a Thinking Process, Not a Planning Process # Strategy is not a document. Strategy is a discipline of reasoning.\nRoger Martin emphasizes that strategy must be a live, iterative exploration of possibilities and trade-offs, not a mechanical planning cycle. This aligns closely with the approach popularized by IDEO, whose human-centered design methodology treats strategy as an iterative process of reframing problems, generating hypotheses, and testing them in the real world. Their perspective on strategic planning (summarized in IDEO U’s article “Strategic Planning: How to Get Started”) reinforces that leaders must be in the room, actively shaping choices, not passively reviewing decks assembled by others.\nBoth Martin and IDEO converge on the same truth: Great strategy emerges from engaged, creative, participatory thinking—not from documents produced in advance of that thinking.\nWhen leaders engage directly with ambiguity, pressure-test assumptions, and co-create choices, strategy becomes real. When they review a “strategy deck” created elsewhere, it becomes performative. This difference—participation versus observation—is often the difference between strategic clarity and strategic theatre.\nImplications for Strategy Advisors (and Internal Strategy Teams) # For advisors—whether internal or external—this redefines the job:\n1. Advisor as Thinking Partner, Not Author of Strategy # Your value is not writing a plan. Your value is provoking sharper thinking, structuring choices, and challenging assumptions.\n2. Protect the Integrity of the Process # Ensure all analysis is in service of the questions leaders themselves care about. Kill all pre-work that implicitly sets direction without shared ownership.\n3. Anchor on the Choices That Matter # Where to play. How to win. What capabilities and management systems must be built. These choices—and only these—define strategy.\n4. Clarify Ownership Every Step of the Way # Strategy belongs to the ELT. The board challenges and endorses. Advisors facilitate. No one else decides.\nThis is a quick win any advisor can bring to the table: eliminate agenda-driven pre-work and put ownership back where it belongs.\nWhy This Matters Now # Companies today face infinite information, rapid change, and constant noise. Teams crave anchors: something stable and durable that guides decisions even as circumstances change.\nRoger Martin’s framing makes strategy more like values: Timeless until the leadership chooses to change it.\nStrategy cannot be allowed to drift with each planning cycle or each incoming deck. It must remain a coherent set of choices that guide the company until new choices explicitly replace them.\nConclusion: Start With the Truth, End With Shared Choices # If I summarize Martin’s argument in one sentence, it is this:\nStrategy starts with the truth about past choices, lives in the heads of accountable leaders, and succeeds only when those leaders make new choices that close the gap between aspiration and outcome.\nI’ve seen the cost of doing it the wrong way: months of preparation, enormous decks, and a strategy no one believes in.\nAnd I’ve seen the impact of doing it the right way: small rooms, honest conversations, and choices that actually change behaviour, investment, and outcomes.\nThe difference is not process. The difference is ownership.\nLeadership owns strategy—or you don’t have one.\n","date":"23 November 2025","externalUrl":null,"permalink":"/articles/strategy-prework/","section":"Articles","summary":"Most corporate “strategy” work starts with months of pre-work and thick decks, and never reaches the real question: why did our past choices produce the results they did? Drawing on Roger Martin’s strategy-as-choices framework, I argue that strategy must begin with the gap between intent and outcome and remain the direct responsibility of the executive leadership team.","title":"If Your Strategy Starts With a Deck, It’s Already Wrong","type":"articles"},{"content":"Astrophysicist turned Fintech CEO Applying the rigor of astrophysics to the chaos of fintech innovation. Bridging technology, capital, and leadership for the next generation of transformative ventures\nI’m a financial services executive and technology advisor with over 25 years of experience leading transformation across banking, insurance, and commercial software. Most recently, I served as President \u0026amp; CEO of UBX, the fintech and corporate venture capital arm of UnionBank of the Philippines, where we built the country’s leading embedded finance platform from the ground up. Over six years, I scaled the business from concept to industry leadership, launched multiple ventures through a venture studio model, secured strategic investment from SBI Holdings of Japan, and introduced the Philippines’ first central bank recognized stablecoin and blockchain-based settlement network. My career has always centered on the intersection of technology, capital, and leadership: turning ideas into scalable, measurable value.\nToday, I work with financial institutions, venture studios, startups and investors across Southeast Asia and North America to help them transform, innovate, and build institutional-grade digital capabilities. My focus is on making innovation investable: designing the systems, governance, and operating models that allow organizations to grow sustainably and confidently. Whether advising CEOs, shaping strategy, or structuring deals, I bring a balance of vision and execution that aligns teams, accelerates outcomes, and builds long-term resilience.\nHaving worked across Canada, the United States, and Asia, I bring a global perspective to how financial systems evolve and how emerging markets leapfrog technology. I’m committed to strengthening innovation ecosystems, developing leaders, and advancing responsible transformation that expands access, opportunity, and economic participation.\n","date":"22 November 2025","externalUrl":null,"permalink":"/about/","section":"John Januszczak | Fintech \u0026 Innovation Strategy","summary":"","title":"About","type":"page"},{"content":"","date":"22 November 2025","externalUrl":null,"permalink":"/tags/design/","section":"Tags","summary":"","title":"Design","type":"tags"},{"content":"Git is a case study on cleverly designing around constraints vs throwing hardware at a problem\nThe Big Picture # The Git object layout is a classic case of \u0026ldquo;design around the actual constraints\u0026rdquo; instead of assuming \u0026ldquo;hardware will save us.\u0026rdquo;\nIn 2005, when Linus Torvalds built Git:\nSpinning hard drives were slow at random seeks and directory lookups. Common filesystems (ext3, NTFS, etc.) choked badly once a directory crossed ~10,000–20,000 entries. A busy Linux kernel repository could easily generate hundreds of thousands of objects over time. SSDs basically didn’t exist for consumers, and even if you had fast hardware, many developers were on laptops or shared servers with mediocre disks. Throwing \u0026ldquo;faster hardware\u0026rdquo; at it wouldn’t have helped most users, and it certainly wouldn’t have made Git usable on large projects back then. Instead, Linus chose a tiny, zero-cost software fix: split into 256 subdirectories using the first two hex digits of the hash. It costs almost nothing in code complexity, adds no runtime overhead, and completely sidesteps the filesystem pathology.\nIt’s a textbook example of thoughtful systems design:\nSolves the real bottleneck (filesystem behavior) rather than a symptom. Scales from tiny repos to monstrous ones with no configuration changes. Still beneficial today even on NVMe SSDs and modern filesystems (fewer directory entries = fewer inodes, less metadata pressure, faster clones on network filesystems, etc.). You see the same philosophy elsewhere in Git: content-addressed storage, Merkle-tree history, packfiles, delta compression… almost everything is built to be stingy with I/O and robust on slow or unreliable hardware, because that was the reality when it was born. Faster CPUs and SSDs are nice bonuses, but Git didn’t need to wait for them to be blazingly fast.\nUnder the Covers # Git stores objects (blobs, trees, commits, and tags) in the .git/objects directory using a loose object format by default. Each object is identified by its SHA-1 hash (a 40-character hexadecimal string, e.g., a1b2c3d4... for SHA-1; Git now uses SHA-256 in some cases, but the structure is similar).\nWhen storing a loose object:\nThe first two characters of the hash become a subdirectory name (e.g., a1). The remaining characters become the filename inside that subdirectory (e.g., b2c3d4...). So an object with hash a1b2c3d4e5f6... ends up at .git/objects/a1/b2c3d4e5f6....\nWhy This Specific Structure? # This is a deliberate performance optimization for filesystem efficiency:\nAvoids huge flat directories\nMany filesystems (especially ext3/ext4 in older configurations, ReiserFS, NTFS, and others common in the mid-2000s when Git was created) slow down dramatically or even have hard limits when a single directory contains tens or hundreds of thousands of files.\nDirectory listing (readdir), lookups, and metadata operations become O(n) or worse. Real-world examples: the Linux kernel repo can have millions of objects over time; putting them all directly under .git/objects/ would make operations painfully slow. \u0026ldquo;Fan-out\u0026rdquo; with exactly 256 subdirectories\nUsing the first two hex characters creates 256 possible subdirectories (00 to ff).\nThis spreads objects roughly evenly (assuming uniform hash distribution). Even in a repository with millions of objects, each subdirectory typically holds only a few thousand files — a number most filesystems handle efficiently. The top-level .git/objects/ directory itself stays tiny (just 256 entries + pack/ and info/). One level is enough; deeper would be overkill\nTwo characters (1 byte) → 256 buckets → sufficient for virtually all repositories. Using three characters (4096 subdirectories) would add unnecessary depth and overhead for typical repos. Linus Torvalds and early Git developers chose this as a pragmatic sweet spot based on real filesystem behavior at the time. Bonus: Fast partial-hash lookups\nWhen you type a short unique hash (e.g., git show a1b2c3), Git only has to look in one specific subdirectory (.git/objects/a1/) and do a simple filename prefix match — very fast, even without an index.\nWhat Happens Later? # New objects start as loose (one file per object). Over time, git gc packs them into efficient packfiles (.git/objects/pack/) for storage and transfer, where this directory structure is no longer used. The fan-out is mainly for the loose phase.\nThis design has proven extremely effective and is why Git repositories remain fast even when they contain hundreds of thousands or millions of objects.\n","date":"22 November 2025","externalUrl":null,"permalink":"/articles/git-design/","section":"Articles","summary":"Explains why Git stores loose objects in 256 subdirectories keyed by the first two hash characters and how that simple layout optimizes filesystem performance and scalability.","title":"Designing Around Constraints","type":"articles"},{"content":"","date":"22 November 2025","externalUrl":null,"permalink":"/tags/technology/","section":"Tags","summary":"","title":"Technology","type":"tags"},{"content":"","date":"6 November 2025","externalUrl":null,"permalink":"/tags/blockchain/","section":"Tags","summary":"","title":"Blockchain","type":"tags"},{"content":"","date":"6 November 2025","externalUrl":null,"permalink":"/tags/cryptocurrency/","section":"Tags","summary":"","title":"Cryptocurrency","type":"tags"},{"content":"","date":"6 November 2025","externalUrl":null,"permalink":"/tags/economics/","section":"Tags","summary":"","title":"Economics","type":"tags"},{"content":"","date":"6 November 2025","externalUrl":null,"permalink":"/tags/fintech/","section":"Tags","summary":"","title":"Fintech","type":"tags"},{"content":"","date":"6 November 2025","externalUrl":null,"permalink":"/tags/money/","section":"Tags","summary":"","title":"Money","type":"tags"},{"content":"As finance evolves from physical to digital to decentralized, remembering stories like the Yap reminds us that money has always been a social technology: built on belief, not metal or code.\nDeep in the western Pacific Ocean, within the Federated States of Micronesia, lies the island state of Yap. While the archipelago is defined by its lush landscapes and enduring indigenous traditions, the Yapese people are globally renowned for an economic phenomenon that seems to defy modern logic: the \u0026ldquo;Rai.\u0026rdquo; These massive, donut-shaped limestone discs served as a currency system that functioned without banks or written records. While often treated as a historical curiosity, the Yapese invention was actually a sophisticated financial instrument that mastered the abstract nature of value long before the rest of the world caught up.\nThe Oldest Blockchain? # The oldest \u0026ldquo;blockchain” wasn’t digital. It was literally carved in stone on a remote Pacific island.\nWhat Yap stone money can teach us about modern finance # Long before blockchain, Yap Island in Micronesia had already solved the hardest problem in finance: how to make money valuable.\nTheir currency: massive carved limestone disks called Rai, couldn’t even be moved. Some were four meters wide. Yet everyone on the island knew who owned which stone, even when it sat untouched in a village far away.\nWhat gave these stones value wasn’t metal or movement. It was trust, scarcity, and shared belief:\nScarcity: Each Rai stone was hard to quarry and dangerous to transport from Palau. Supply was naturally limited. Proof of work: The bigger and riskier the expedition, the greater the value. Effort was literally embedded in the asset. Consensus ledger: Ownership was recorded collectively, not physically. In a sense, Yap invented the first distributed ledger centuries before Bitcoin. History as value: Stones with rich stories like shipwrecks, deaths, or heroic voyages traded at premiums. Narrative shaped valuation, just as brand and provenance do today. The \u0026ldquo;Central Banker\u0026rdquo; Who Broke the Peg # The system worked perfectly for centuries until 1871, when a shipwrecked Irish-American captain named David O’Keefe washed ashore.\nO’Keefe was an entrepreneur, not an anthropologist. He noticed that the Yapese had little interest in his foreign currency, but they were desperate for Rai stones. He also saw an arbitrage opportunity. The Yapese were quarrying these stones using shell tools and transporting them on bamboo canoes—a process so dangerous that many died on the return journey.\nO’Keefe saw a \u0026ldquo;technology gap.\u0026rdquo; He sailed to Palau equipped with modern iron tools and a large Chinese junk. He didn\u0026rsquo;t just quarry stones; he mass-produced them.\nHe returned to Yap with stones larger and more perfectly carved than anything the island had seen before. He used these stones to \u0026ldquo;buy\u0026rdquo; the island’s copra (coconut meat) and sea cucumber harvest, effectively becoming the wealthiest man in the region—the self-styled \u0026ldquo;King of Yap.\u0026rdquo;\nHowever, the island’s elders (the \u0026ldquo;nodes\u0026rdquo; of this network) rejected O’Keefe’s stones. They instinctively understood that the value of the Rai wasn\u0026rsquo;t in the limestone itself, but in the human struggle required to obtain it. Because O’Keefe’s stones came without risk or sacrifice—without \u0026ldquo;Proof of Work\u0026rdquo;—they were deemed to have a fraction of the value of the older, smaller stones.\nIt was history\u0026rsquo;s first instance of a \u0026ldquo;hard fork.\u0026rdquo; The market split into two tiers: the highly valued traditional stones (Bitcoin?) and the abundant, technologically easy O’Keefe stones (a fiat currency prone to inflation).\nIn short, those newer stones became less valuable, proof that ease of creation dilutes worth. The Yapese intuitively understood inflation centuries before economists did.\nWhat Makes Money Real # Today, whether it’s central bank digital currencies, stablecoins, or tokenized deposits, the same forces still define what makes “money” real:\nScarcity Difficulty of production Consensus on ownership Trust in the system that keeps the ledger From Rai stones to reserves to digital tokens: it’s the same story told in different materials.\nFeature image credit: Eric Guinther, CC BY-SA 3.0 via Wikimedia Commons\n","date":"6 November 2025","externalUrl":null,"permalink":"/articles/yap-stone-money/","section":"Articles","summary":"Long before digital wallets, the people of Yap solved the hardest problems in finance using 4-ton limestone rocks. This article explores how ancient \u0026lsquo;Rai\u0026rsquo; stones utilized the same principles—scarcity, consensus, and proof-of-work—that underpin modern digital currencies and blockchain technology today.","title":"The Original Blockchain Was Carved in Stone","type":"articles"},{"content":"","date":"24 September 2025","externalUrl":null,"permalink":"/tags/banking/","section":"Tags","summary":"","title":"Banking","type":"tags"},{"content":"","date":"24 September 2025","externalUrl":null,"permalink":"/tags/digital/","section":"Tags","summary":"","title":"Digital","type":"tags"},{"content":"","date":"24 September 2025","externalUrl":null,"permalink":"/tags/external/","section":"Tags","summary":"","title":"External","type":"tags"},{"content":"","date":"4 June 2025","externalUrl":null,"permalink":"/tags/cbdc/","section":"Tags","summary":"","title":"CBDC","type":"tags"},{"content":"","date":"4 June 2025","externalUrl":null,"permalink":"/tags/defi/","section":"Tags","summary":"","title":"DeFi","type":"tags"},{"content":"","date":"15 May 2025","externalUrl":null,"permalink":"/tags/payments/","section":"Tags","summary":"","title":"Payments","type":"tags"},{"content":"","date":"15 May 2025","externalUrl":null,"permalink":"/tags/stablecoins/","section":"Tags","summary":"","title":"Stablecoins","type":"tags"},{"content":"How x402 is changing the payments landscape\nWhy are online payments still stuck in 1999? While the web evolved from static pages to dynamic apps, and AI agents now act autonomously across the internet, the way we pay online hasn’t kept up. That’s about to change.\nThe Report # This 17-page report explores x402, a new protocol by Coinbase that activates the web’s long-dormant payment layer: HTTP 402 – Payment Required.\nInside the Report:\nWhy HTTP was always meant to include payments How PayPal and Stripe solved for speed—but not autonomy Why modern payment systems fail for AI agents, APIs, and micropayments How x402 enables instant, autonomous payments using stablecoins The end of subscriptions? How x402 could disrupt SaaS and banking models The Audience # This report is relevant for fintech founders, internet infrastructure builders, Web3 and AI developers, product managers, protocol thinkers, and investors looking for an overview of the history of payments on the web, the challenges we face today, and looking ahead with a protocol like x402.\nWhat you’ll get # A beautifully written, digestible PDF (17 pages) Instant access Exclusive updates on future essays, protocols, and tools reshaping digital finance Stripe made payments easy. x402 makes payments native. Get ahead of the next shift in internet infrastructure.\nDownload the report. Join the conversation. Shape what’s next.\n","date":"15 May 2025","externalUrl":null,"permalink":"/articles/x402-intro/","section":"Articles","summary":"The internet\u0026rsquo;s \u0026lsquo;original sin\u0026rsquo; was the lack of a native payment layer. This report explores x402, a new protocol that utilizes the HTTP 402 status code to enable instant, autonomous stablecoin payments for AI agents and the modern web.","title":"The Next Chapter of the Web","type":"articles"},{"content":"Central Bank Digital Currencies will redefine money. We may be surprised by the implications.\nAdoption to Date # Central banks are actively looking at, or already developing Central Bank Digital Currency (CDBC). At last count, 11 nations already have CBDCs with over 20 piloting it in some way.\nIn the Philippines, the Bangko Sentral ng Pilipinas is currently conducting Project Agila to pilot a wholesale CBDC.\nThe Implications # Along with stablecoins, the killer use case for CBDC is settlement. While compelling, we need to understand that digitally native currency will change the very nature of money as we know it.\nBy championing digital payments, central banks are effectively digitizing bank notes via electronic money and/or central bank sanctioned stablecoins. Wholesale CBDC stands to digitize the ledger of bank reserves held by a central bank. Together, base money becomes entirely digital and programmable.\nThe Impact? # Better Control Over Use of Money # It will become easy to track who is using each unit of currency and enforce how it is used. CBDCs (and digital currency that settles to it), for example, can mitigate money laundering and fraud directly at the currency level. This is a huge win for banks that struggle to comply with sub-optimal, if not outright ineffective, AML implementations.\nFlexible Monetary Policy # CDBCs allow a finer level of monetary policy. Why do we have one interest rate for an entire country? Rates could be set and enforced for any sub segment of an economy. By controlling the costs of capital at a granular level, regulators can expand specific industries by targeting monetary policy via CDBCs (and digital currencies which rely on them). For example, incentivizing chip manufacturing while de-priotizing internal combustion automobile production. Money could be programmed to literally expire to encourage spending.\nExpand Boundaries of Monetary Policy # CBDCs could make negative interest rates actually work when the central bank wants to stimulate the economy. Today, physical cash effectively puts a lower limit on how negative you can go because holding it is essentially a zero interest rate option on currency.\nSimplifying Cross Border Transactions # Yes, this is the killer use case, but it too has implications. CDBCs will allow central banks and cross border commerce to bypass the US banking system. This is actively happening with the Bank of International Settlement\u0026rsquo;s (BIS) mBridge project with participation from five central banks leading up to an MVP in the near term.\nCentral Bank Agenda # Central banks have every reason to digitize currency (and eliminate cash). I think that\u0026rsquo;s why we are seeing the rapid global uptick in adoption.\nWhat do you think? Do we fully understand the implications of CBDCs? Are there others to consider?\n","date":"11 June 2024","externalUrl":null,"permalink":"/articles/cbdc/","section":"Articles","summary":"An analysis of the global shift toward Central Bank Digital Currencies (CBDCs), highlighting the transition from physical cash to programmable money. The article explores how CBDCs—exemplified by initiatives like the Philippines\u0026rsquo; Project Agila and the BIS mBridge project—will revolutionize monetary policy through granular control, improved AML compliance, and new cross-border settlement rails.","title":"Central Bank Digital Currencies will Redefine Money","type":"articles"},{"content":"","date":"11 June 2024","externalUrl":null,"permalink":"/tags/monetary-policy/","section":"Tags","summary":"","title":"Monetary Policy","type":"tags"},{"content":"","date":"1 June 2024","externalUrl":null,"permalink":"/tags/customer-experience/","section":"Tags","summary":"","title":"Customer Experience","type":"tags"},{"content":"","date":"1 June 2024","externalUrl":null,"permalink":"/tags/management/","section":"Tags","summary":"","title":"Management","type":"tags"},{"content":"","date":"1 June 2024","externalUrl":null,"permalink":"/tags/operations/","section":"Tags","summary":"","title":"Operations","type":"tags"},{"content":"","date":"1 June 2024","externalUrl":null,"permalink":"/tags/productivity/","section":"Tags","summary":"","title":"Productivity","type":"tags"},{"content":"The Math of Responsiveness: Why Speed is a Strategy\nIn over 25 years of leading transformation across banking, fintech, and insurance, I have observed a distinct correlation between high-performance teams and the speed of their communication.\nToo often, organizations tolerate a \u0026ldquo;laissez-faire\u0026rdquo; culture regarding responsiveness under the guise of productivity. We tell ourselves we are too busy \u0026ldquo;doing the work\u0026rdquo; to reply. But how we close sales, how we build loyalty, and how we show respect to our partners (and each other!) are all predicated on how responsive we are.\nI have long argued that high-touch service is a precursor to scale. Responsiveness is often the only safety net that exists when other systems and processes fail.\nThe Misconception: Value vs. Speed # Most professionals misunderstand responsiveness. We think it is purely dependent on delivering value: the completed analysis, the full proposal, or the final answer. Consequently, we wait until we have the \u0026ldquo;whole thing\u0026rdquo; before hitting reply.\nHowever, the hidden component of responsiveness is simply speed.\nIdeally, you provide both speed and value. But when you cannot, you must always err on the side of speed. It is perfectly acceptable not to know the answer immediately; it is not acceptable to leave a stakeholder hanging while you search for it.\nHere is the math:\nResponsiveness = Speed + Value (Where Speed \u0026gt; Delayed Value)\nThe Responsiveness Recipe # To operationalize this, I recommend a simple three-step protocol that works for executives, developers, sales teams, and all teams alike:\n1. The Immediate Solve (The Ideal) Ideally, you respond immediately with the value requested. In customer experience, we call this \u0026ldquo;First Contact Resolution.\u0026rdquo; This includes providing the proposal, the opinion, or the document right then and there.\n2. The Commitment (The Reality) If you cannot provide the value immediately, you must acknowledge the request instantly and provide a commitment to a timeline.\nDon\u0026rsquo;t say: \u0026ldquo;Let me get back to you.\u0026rdquo; Do say: \u0026ldquo;I need time to process this properly. I will revert by the end of the week.\u0026rdquo; This step is critically important. By replying right away with a date and time, you are managing expectations and preventing the counterparty from feeling ignored.\n3. The Reset (The Safety Net) If you cannot meet the deadline you committed to in Step 2, you must reset expectations before the deadline passes. Because you set a timeline, you can set a reminder for yourself. If you are running behind, reach out proactively: \u0026ldquo;I promised this analysis by tomorrow. I need more time to do this properly. I will provide it three days from now.\u0026rdquo;.\nI illustrate the protocol below: Responsiveness infographic by author A Note for the Technical Mind # For those with a background in technology or systems integration, this concept should sound familiar.\nThis protocol is essentially the human equivalent of an Event Manager handling long-running web requests. You use asynchronous request processing to set expectations and communicate updates to the client application, rather than letting the connection time out.\nThe Bottom Line # Responsiveness does not require a budget, a support team, or complex software. It requires only personal commitment.\nWhether you are building a venture from zero to scale or managing a complex corporate ecosystem, your future is in your hands. Confront the urge to delay. Prioritize speed.\n","date":"1 June 2024","externalUrl":null,"permalink":"/articles/responsiveness/","section":"Articles","summary":"Ideally, you provide value immediately. When you can\u0026rsquo;t, you provide speed. Here is the simple math behind high-performance communication that builds trust and loyalty.","title":"Responsiveness","type":"articles"},{"content":"","date":"23 May 2024","externalUrl":null,"permalink":"/tags/embedded-finance/","section":"Tags","summary":"","title":"Embedded Finance","type":"tags"},{"content":"","date":"23 May 2024","externalUrl":null,"permalink":"/tags/open-finance/","section":"Tags","summary":"","title":"Open Finance","type":"tags"},{"content":" If you strip away the jargon, the regulatory frameworks, and the complex APIs, Open Finance is actually a very simple concept.\nIt boils down to one fundamental truth: The data financial institutions hold on their customers belongs to the customers, not the financial institutions.\nIt is really that simple.\nI discuss this extensively in the video below (jump to the 15:37 mark for the deep dive), but I want to highlight why this shift is so critical for us here in the Philippines.\nWhy the Philippines Needs a Broader View # While the concept of data ownership is universal, its application in the Philippines requires a much broader lens. In many developed markets, Open Banking focuses on aggregating bank accounts. But here, that isn\u0026rsquo;t enough.\nTo truly unlock financial inclusion, we need to look beyond traditional banking data. We require a system where consumer consent unlocks a massive variety of data points—from utility payments to e-wallet transactions.\nWhy? Because we have a massive population of \u0026ldquo;invisible\u0026rdquo; consumers who are financially responsible but lack a formal credit history.\nWe need access to huge amounts of data to uncover patterns: the subtle digital footprints that attest to a person\u0026rsquo;s credibility and creditworthiness. By analyzing these patterns, we can prove that a customer is reliable, even if they\u0026rsquo;ve never held a credit card in their life.\nOpen Finance isn\u0026rsquo;t just about moving data; it\u0026rsquo;s about moving people from \u0026ldquo;unbanked\u0026rdquo; to \u0026ldquo;bankable.\u0026rdquo;\nWatch the section starting at 15:37 to understand how this simple shift in ownership can revolutionize our financial landscape.\n","date":"23 May 2024","externalUrl":null,"permalink":"/videos/open-finance-anc/","section":"Videos","summary":"Open Finance is really quite simple: the data financial institutions hold on their customers belongs to their customers. But for the Philippines, we require a much broader view of what needs to be open and shareable to verify credibility.","title":"Unlocking the Value of Open Finance","type":"videos"},{"content":"Selected appearances where I discuss the trends and technologies reshaping business. From media interviews to keynote presentations, these videos highlight the perspectives I’ve shared with executives, policymakers, and innovators across the region.\n","date":"23 May 2024","externalUrl":null,"permalink":"/videos/","section":"Videos","summary":"","title":"Videos","type":"videos"},{"content":"","date":"1 January 2024","externalUrl":null,"permalink":"/tags/cleantech/","section":"Tags","summary":"","title":"CleanTech","type":"tags"},{"content":"","date":"1 January 2024","externalUrl":null,"permalink":"/tags/distributed-energy/","section":"Tags","summary":"","title":"Distributed Energy","type":"tags"},{"content":"","date":"1 January 2024","externalUrl":null,"permalink":"/tags/electric-vehicles/","section":"Tags","summary":"","title":"Electric Vehicles","type":"tags"},{"content":"","date":"1 January 2024","externalUrl":null,"permalink":"/tags/energy-transition/","section":"Tags","summary":"","title":"Energy Transition","type":"tags"},{"content":"Incubation. Investment. Impact.\nCapital is a commodity; execution is the differentiator. This portfolio highlights the ventures where I have led the deployment of not just capital, but active governance and operational leadership.\nI embed deeply as an operational lead and board director to de-risk execution and accelerate the path to liquidity. Below are the ventures where I’ve had the privilege of rolling up my sleeves.\n","date":"1 January 2024","externalUrl":null,"permalink":"/portfolio/","section":"Portfolio","summary":"","title":"Portfolio","type":"portfolio"},{"content":"","date":"1 December 2023","externalUrl":null,"permalink":"/tags/consumer-finance/","section":"Tags","summary":"","title":"Consumer Finance","type":"tags"},{"content":"","date":"1 December 2023","externalUrl":null,"permalink":"/tags/solar/","section":"Tags","summary":"","title":"Solar","type":"tags"},{"content":"","date":"12 November 2023","externalUrl":null,"permalink":"/tags/history/","section":"Tags","summary":"","title":"History","type":"tags"},{"content":" The End of \u0026ldquo;Emerging\u0026rdquo; Tech: Why the Future of Banking Looks Like Nothing We’ve Seen Before # \u0026ldquo;Blockchain, Internet of Things, Artificial Intelligence—these are not emerging technologies. They have already emerged.\u0026rdquo;\nI tried to give a thought-provoking keynote at the Asia Bank Tech Forum 2023 and challenged the audience to rethink their definition of innovation. I argued that the technologies we obsess over today are merely tomorrow\u0026rsquo;s legacy systems. To understand where banking is going, we first have to understand the history of how humans get work done.\nHere are the key takeaways from the talk on the true path to the next generation of banking.\nThe Evolution of Productivity # Human history can be broken down into three distinct phases of work, moving from linear to exponential growth:\nThe Manual Age (Linear): For thousands of years—from early agriculture to the Medici banks of the 1400s—productivity was tied strictly to population. If you wanted more output, you needed more people. The formula was simple: Humans took data, applied rules, and got an answer. The Industrial Revolution (Assisted): Machines began assisting humans. While the paradigm remained the same (applying rules to data), the efficiency of machines allowed production to finally outpace population growth. The Information Age (Automated): Computers changed the game by allowing us to feed rules into a machine before doing the task. This allowed for consistent, repeatable automation—the birth of modern digital banking. This history of mechanization explains why production has exploded over the last 60 years. However, we are now entering a fourth, radically different phase.\nThe AI Paradigm Shift: Flipping the Script # The most profound insight from this talk is a fundamental shift in how we process information. For the first time in history, we aren\u0026rsquo;t just automating rules; we are discovering them.\nThe Old Way: We feed Data + Rules into the machine → We get Answers. The AI Way: We feed Data + Answers into the machine → We get Rules. This is a massive shift. We currently generate 2.5 quintillion bytes of data daily, yet we utilize less than 1% of it because we are limited by the rules we currently know. Machine learning allows us to uncover rules for things we couldn\u0026rsquo;t previously define—like language, thought, and image recognition.\nBanking is Necessary, Banks Are Not # As technology evolves, the \u0026ldquo;bank\u0026rdquo; as a physical location or distinct entity is disappearing. Bill Gates’ famous 1994 prediction: \u0026ldquo;Banking is necessary, but banks are not\u0026rdquo;.\nWe are seeing this reality today. Airlines like ANA are becoming banks, and open banking platforms are empowering thousands of small businesses to provide banking utility to their local communities. The future of finance is not just digital; it is open, embedded, and decentralized.\nWhat Does the Future Look Like? # If AI is writing the rules, where does that leave us? The honest answer is: We don\u0026rsquo;t know.\nBecause the new paradigm generates rules from data rather than human logic, the future of banking will likely look like nothing we have seen before. However, the potential is limitless. The goal isn\u0026rsquo;t just better technology; it is total inclusion.\nThe ultimate question isn\u0026rsquo;t about the tech itself, but the outcome: \u0026ldquo;What will it look like when all 115 million Filipinos are connected without any barrier to the global economy?\u0026rdquo;.\nWant to dive deeper into the shift from linear banking to exponential fintech? Watch the full video to see how the financial services ecosystem will leverage these levers to achieve 10x growth.\n","date":"12 November 2023","externalUrl":null,"permalink":"/videos/next-gen-bank-tech/","section":"Videos","summary":"John Januszczak outlines the transition from linear banking to exponential fintech growth using AI, Open Finance, and Embedded ecosystems.","title":"Next Generation Banking Technology","type":"videos"},{"content":"","date":"12 November 2023","externalUrl":null,"permalink":"/tags/transformation/","section":"Tags","summary":"","title":"Transformation","type":"tags"},{"content":"","date":"1 June 2023","externalUrl":null,"permalink":"/tags/agritech/","section":"Tags","summary":"","title":"AgriTech","type":"tags"},{"content":"","date":"1 June 2023","externalUrl":null,"permalink":"/tags/foodtech/","section":"Tags","summary":"","title":"FoodTech","type":"tags"},{"content":"","date":"1 June 2023","externalUrl":null,"permalink":"/tags/msme/","section":"Tags","summary":"","title":"MSME","type":"tags"},{"content":"","date":"1 June 2023","externalUrl":null,"permalink":"/tags/supply-chain/","section":"Tags","summary":"","title":"Supply Chain","type":"tags"},{"content":"","date":"6 February 2023","externalUrl":null,"permalink":"/tags/bnpl/","section":"Tags","summary":"","title":"BNPL","type":"tags"},{"content":"","date":"2 February 2023","externalUrl":null,"permalink":"/tags/ekyc/","section":"Tags","summary":"","title":"EKYC","type":"tags"},{"content":"","date":"2 February 2023","externalUrl":null,"permalink":"/tags/identity/","section":"Tags","summary":"","title":"Identity","type":"tags"},{"content":"","date":"2 February 2023","externalUrl":null,"permalink":"/tags/regtech/","section":"Tags","summary":"","title":"RegTech","type":"tags"},{"content":"","date":"1 January 2023","externalUrl":null,"permalink":"/tags/agency-banking/","section":"Tags","summary":"","title":"Agency Banking","type":"tags"},{"content":"","date":"1 January 2023","externalUrl":null,"permalink":"/tags/financial-inclusion/","section":"Tags","summary":"","title":"Financial Inclusion","type":"tags"},{"content":"","date":"1 January 2023","externalUrl":null,"permalink":"/tags/pos/","section":"Tags","summary":"","title":"POS","type":"tags"},{"content":"","date":"10 June 2022","externalUrl":null,"permalink":"/tags/nft/","section":"Tags","summary":"","title":"NFT","type":"tags"},{"content":"","date":"10 June 2022","externalUrl":null,"permalink":"/tags/wealth/","section":"Tags","summary":"","title":"Wealth","type":"tags"},{"content":"","date":"10 June 2022","externalUrl":null,"permalink":"/tags/web3/","section":"Tags","summary":"","title":"Web3","type":"tags"},{"content":"","date":"12 November 2021","externalUrl":null,"permalink":"/tags/api/","section":"Tags","summary":"","title":"API","type":"tags"},{"content":"","date":"12 November 2021","externalUrl":null,"permalink":"/tags/baas/","section":"Tags","summary":"","title":"BaaS","type":"tags"},{"content":"","date":"12 November 2021","externalUrl":null,"permalink":"/tags/ethereum/","section":"Tags","summary":"","title":"Ethereum","type":"tags"},{"content":"","date":"12 November 2021","externalUrl":null,"permalink":"/tags/infrastructure/","section":"Tags","summary":"","title":"Infrastructure","type":"tags"},{"content":"","date":"12 November 2021","externalUrl":null,"permalink":"/tags/wallet/","section":"Tags","summary":"","title":"Wallet","type":"tags"},{"content":"","date":"9 September 2021","externalUrl":null,"permalink":"/tags/proptech/","section":"Tags","summary":"","title":"PropTech","type":"tags"},{"content":" Real estate is one of the most meaningful economic and personal experiences people have: where we live, work, build communities, and invest for the future. Yet for all its significance, it remains one of the most digitally underserved and financially inaccessible sectors in the Philippines.\nIn this 2021 talk, I explored how property technology (\u0026ldquo;PropTech\u0026rdquo;) can reshape the country’s real estate landscape by embedding financial services and unlocking inclusive participation. The opportunity is enormous: real estate is the second-largest asset class in the world, and in the Philippines it continues to experience strong demand and growth. But it is also illiquid, costly, and accessible to only a very small segment of the population.\nWhy Tokenization Matters # Our hypothesis is simple: the future belongs to invisible, embedded financial services, financial capabilities built seamlessly into the experiences that matter most. Real estate is exactly such an experience. That belief led us to develop a platform for tokenizing real estate assets, breaking a property into digital, fractionalized tokens that investors can buy, trade, and hold just like any other financial asset.\nTokenization promises three major benefits: # 1. Liquidity Real estate in the Philippines is still largely illiquid, with limited participation even in REITs. Digitally tradable tokens can unlock a secondary market and bring flexibility to a traditionally rigid asset class.\n2. Lower Costs High transaction costs—taxes, fees, commissions—add substantial friction. Tokenization creates room for more transparent and streamlined processes.\n3. Democratization Today, real estate investing is binary: you buy the whole thing, or you don’t. Fractional ownership lets ordinary Filipinos participate in the country’s fastest-growing asset class, often for the first time.\nWhat We Built # The venture described in the video (temporarily paused due to the pandemic) consisted of three layers:\nA digital marketplace with wallet, KYC, and investment onboarding A tokenization engine that fractionalizes vetted properties and automates yields, income distribution, and rights through smart contracts A secondary trading market powered through our strategic partnership and investment in a BSP-regulated digital asset exchange (e.g. PDAX) To support this ecosystem, we also integrated lending, insurance, and seamless cash-in/cash-out services—embedding financial services directly within the real estate experience.\nThe Barriers That Remain # Tokenization is still in its infancy globally. While the technology is proven, the real challenges lie in:\nTesting the market’s actual appetite for tokenized real estate Structuring appropriate intermediate vehicles (contracts, long-term leaseholds, SPVs) that can legally be tokenized Evolving regulatory frameworks to support crowdfunding, digital asset exchanges, and potentially even blockchain-based titles in the future The Philippines has the opportunity to leapfrog if regulators, property developers, fintechs, and investors move thoughtfully and collaboratively.\nA Path Toward Inclusive Prosperity # Ultimately, PropTech is not simply about technology, it is about economic participation. If we can solve the structural, legal, and regulatory challenges, we can open the doors of real estate investing to millions more Filipinos.\nThat is the promise of PropTech and the reason we continue to explore this space: to move the country toward a future where real estate is not just a privilege for the few, but an accessible investment opportunity for the many.\n","date":"9 September 2021","externalUrl":null,"permalink":"/videos/proptech/","section":"Videos","summary":"Real estate is one of the Philippines’ fastest-growing asset classes—but it remains illiquid, costly, and out of reach for most people. In this talk, I explore how PropTech, tokenization, and embedded finance can democratize property investing.","title":"PropTech and the Future of Real Estate","type":"videos"},{"content":"","date":"9 September 2021","externalUrl":null,"permalink":"/tags/tokenization/","section":"Tags","summary":"","title":"Tokenization","type":"tags"},{"content":"","date":"2 July 2021","externalUrl":null,"permalink":"/tags/insurtech/","section":"Tags","summary":"","title":"InsurTech","type":"tags"},{"content":"","date":"1 April 2021","externalUrl":null,"permalink":"/tags/e-commerce/","section":"Tags","summary":"","title":"E-Commerce","type":"tags"},{"content":"","date":"1 March 2021","externalUrl":null,"permalink":"/tags/fractional-ownership/","section":"Tags","summary":"","title":"Fractional Ownership","type":"tags"},{"content":"","date":"1 March 2021","externalUrl":null,"permalink":"/tags/real-estate/","section":"Tags","summary":"","title":"Real Estate","type":"tags"},{"content":"","date":"26 January 2020","externalUrl":null,"permalink":"/tags/scale/","section":"Tags","summary":"","title":"Scale","type":"tags"},{"content":"","date":"1 December 2019","externalUrl":null,"permalink":"/tags/lending/","section":"Tags","summary":"","title":"Lending","type":"tags"},{"content":"","date":"1 November 2019","externalUrl":null,"permalink":"/tags/saas/","section":"Tags","summary":"","title":"SaaS","type":"tags"},{"content":"","date":"6 September 2019","externalUrl":null,"permalink":"/tags/big-data/","section":"Tags","summary":"","title":"Big Data","type":"tags"},{"content":"","date":"6 September 2019","externalUrl":null,"permalink":"/tags/credit-scoring/","section":"Tags","summary":"","title":"Credit Scoring","type":"tags"},{"content":"","date":"31 July 2019","externalUrl":null,"permalink":"/tags/digital-assets/","section":"Tags","summary":"","title":"Digital Assets","type":"tags"},{"content":"","date":"4 July 2019","externalUrl":null,"permalink":"/tags/enterprise-dlt/","section":"Tags","summary":"","title":"Enterprise DLT","type":"tags"},{"content":"","date":"9 May 2019","externalUrl":null,"permalink":"/tags/logistics/","section":"Tags","summary":"","title":"Logistics","type":"tags"},{"content":"","date":"9 May 2019","externalUrl":null,"permalink":"/tags/supply-chain-finance/","section":"Tags","summary":"","title":"Supply Chain Finance","type":"tags"},{"content":"","date":"1 March 2019","externalUrl":null,"permalink":"/tags/erp/","section":"Tags","summary":"","title":"ERP","type":"tags"},{"content":"","date":"1 March 2019","externalUrl":null,"permalink":"/tags/finance/","section":"Tags","summary":"","title":"Finance","type":"tags"},{"content":"","date":"13 May 2018","externalUrl":null,"permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning","type":"tags"},{"content":"","date":"3 March 2018","externalUrl":null,"permalink":"/tags/insurance/","section":"Tags","summary":"","title":"Insurance","type":"tags"},{"content":"","date":"3 February 2018","externalUrl":null,"permalink":"/tags/vc/","section":"Tags","summary":"","title":"VC","type":"tags"},{"content":"","date":"20 September 2017","externalUrl":null,"permalink":"/tags/asset-management/","section":"Tags","summary":"","title":"Asset Management","type":"tags"},{"content":"","date":"20 September 2017","externalUrl":null,"permalink":"/tags/trust-corporation/","section":"Tags","summary":"","title":"Trust Corporation","type":"tags"},{"content":"","date":"1 December 2011","externalUrl":null,"permalink":"/tags/automation/","section":"Tags","summary":"","title":"Automation","type":"tags"},{"content":"","date":"1 December 2011","externalUrl":null,"permalink":"/tags/bpm/","section":"Tags","summary":"","title":"BPM","type":"tags"},{"content":"","date":"1 December 2011","externalUrl":null,"permalink":"/tags/optimization/","section":"Tags","summary":"","title":"Optimization","type":"tags"},{"content":"","date":"1 December 2011","externalUrl":null,"permalink":"/tags/simulation/","section":"Tags","summary":"","title":"Simulation","type":"tags"},{"content":"","date":"1 December 2011","externalUrl":null,"permalink":"/tags/workflow/","section":"Tags","summary":"","title":"Workflow","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]